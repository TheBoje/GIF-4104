\documentclass[a4paper, french]{article}
\usepackage{config}
\author{Vincent Commin \& Louis Leenart}
\date{\today}
\setcounter{secnumdepth}{6}
\begin{document}

\begin{titlepage}
    \begin{flushleft}
        \includegraphics[width=5cm]{UL.jpg}\par
        \centering

        \vspace{13\baselineskip}
        \HRule \\[0.4cm]

        {\Huge
        GIF-4104 - TP 4\par}
        \vspace{0.4cm}
        \HRule
        \vfill
        Équipe 1 : Vincent Commin \& Louis Leenart\medskip \par
    \end{flushleft}
\end{titlepage}

\newpage
\section{Introduction}

Pour ce quatrième TP, nous avons implémenté la parallélisation d'inversion d'une matrice en utilisant
méthode de \href{https://fr.wikipedia.org/wiki/%C3%89limination_de_Gauss-Jordan}{\textit{\underline{Gauss Jordan}}}
avec  \href{https://www.khronos.org/opencl/}{\textit{\underline{OpenCL}}} et \href{https://www.openacc.org/}{\textit{\underline{OpenACC}}}. En se basant sur l'implémentation séquentielle proposée, nous avons suivi l'approche par réduction puis diffusion successives.

\section{Notre approche}

\subsection{OpenCL}

Dans ce TP, nous avons découvert l'utilisation d'OpenCL ainsi que ses particularités. En implémentant l'algorithme d'inversion de matrix de Gauss Jordan pour une architecture de GPU, nous avions en tête de diminuer le temps de calcul pour qu'il soit inférieur à celui obtenu avec l'utilisation uniquement du CPU.

L'algorithme que nous avons mis en place est le suivant :

\begin{lstlisting}[style=txt]
AI : Matrix [A I] // Shared amoung every GPU threads
Buffer : value array // Shared amoung every GPU
size, rank : integer

FOR k = 0 TO AI.rows DO
    max = 0, pivotIndex = k
    FOR i = k TO AI.rows DO // Find greatest pivot for column k
        IF (i mod size) == rank && abs(AI[i, k]) > max DO
            max = abs(AI[i, k]); pivotIndex = i
        DONE
    DONE

    Buffer[pivotIndex] = max
    pivotIndex = Reduce(MAX_LOG, Buffer) // Location of max value in Buffer

    IF IA[pivotIndex, k] == 0 DO throw exception DONE

    v = AI[k, k] // Normalisation
    FOR j = 0 TO AI.cols DO
        AI[k, j] = AI[k, j] / v
    DONE

    FOR i = 0 TO AI.rows DO // For each rows
        IF i mod size == rank && i != k DO
            AI[i] -= AI[k] * AI[i, k]
        DONE
    DONE
DONE

FOR i = 0 TO AI.rows DO // Copy right side of AI into result
    A = AI.getData()[slice(i * AI.cols + AI.rows, AI.rows, 1)]
DONE
\end{lstlisting}

L'utilisation que nous avons fait d'OpenCL est assez naïve : découvrant le langage, nous avons simplement essayé d'appliquer l'algorithme d'inversion. Pas encore suffisament familier avec les tenants et aboutissants de chacun des paramètres OpenCL, nous avons eu du mal à paramétrer ce dernier pour maximiser les performances. Nous avons par ailleurs remarqué que pour une taille de workgroup plus grande que 128, des erreurs de calculs ont commencé à appaitre, mais nous avons pas réussi à identifier la source de ce problème, c'est pourquoi nous conduirons nos calculs pour des matrix de taille maximum 128 x 128.

D'après les spécifications de la carte graphique utilisée, nous avons décidé d'utiliser un worker group de la taille de la matrice, et donc d'associer une ligne à chacun des worker, ce qui nous a permi d'obtenir les meilleurs résultats. La minimisation de l'accès à la mémoire globale n'a pu être notre priorité, et l'on remarque effectivement que chaque worker accède régulièrement à la mémoire globale ce qui n'est pas obtimal.

\subsection{OpenACC}

Pour la version utilisant OpenACC, nous avons décidé de reprendre le programme séquentiel et d'y ajouter les directives comme il ait conseillé. Nous avons, comme pour le programme OpenCL, décidé de paralléliser la fonction d'inversion de matrice par la méthode de Gauss-Jordan. 

L'algorithme que nous avons mis en place est le suivant : 

\begin{lstlisting}[style=txt]
AI : Matrix [A I]

// local matrix initialize as identity matrix 
// concatenated with the AI matrix
lAI : Identity Matrix [A I] 

// Give lAI and AI matrix as input and output 
// for every inner parallel sections
#pragma acc data copy(lAI, AI)
{
FOR k = 0 TO AI.rows DO
    max = abs(lAI[i, k]), pivotIndex = k
    FOR i = k TO lAI.rows DO // Find greatest pivot for column k
        IF abs(lAI[i, k]) > max DO
            max = abs(lAI[i, k]); pivotIndex = i
        DONE
    DONE

    IF lIA[pivotIndex, k] == 0 DO throw exception DONE

    IF (pivotIndex != k) AI.swapRows(pivotIndex, k)

    v = lAI[k, k] // Normalisation
    // Parrallelize the for loop passing lValue and k as output only
    #pragma acc parallel loop copyin(lValue, k)
    FOR j = 0 TO lAI.cols DO
        lAI[k, j] = lAI[k, j] / v
    DONE

    // Parrallelize the for loop, as k is already present in 
    // the device memory, we reuse it
    #pragma acc parallel loop present(k)
    FOR i = 0 TO lAI.rows DO // For each rows
        IF i != k DO
            lAI[i] = lAI[i] - lAI[k] * v
        DONE
    DONE
DONE

#pragma acc parallel loop
FOR i = 0 TO AI.rows DO // Copy right side of AI into result
    AI[i] = lAI.getData()[slice(i * lAI.cols + AI.cols, AI.cols, 1)]
DONE
}
\end{lstlisting}

L'avantage de OpenACC est de pouvoir réutiliser le code séquentiel afin de la paralléliser. De plus, ce que OpenACC parrallélise le plus facilement sont les boucles, c'est pour cela que toutes les directives se trouvent aux abords de celles-ci. Avant d'utiliser les directives de parallélisation, nous faisons appel à la directive \textbf{data} qui nous permet de passer les matrices \textbf{lAI} et \textbf{AI} en lecture et écriture à toutes les autres directives de parallélisation inclues dans cette directive \textbf{data}.

Pour la première boucle récupérant l'index du maximum, il aurait été intéressant d'utilisant la clause de réduction sur la fonction \textbf{max}. Cependant, cela est rendu impossible par l'assignation de l'index. Nous avons donc fait le choix de ne pas paralléliser cette boucle, cela aurait été du calcul redondant sur tout les threads ce qui aurait diminué l'efficacité. 

\section{Machine utilisée pour les tests de performance}

\begin{center}
    \begin{tabularx}{0.6\textwidth}{|>{\raggedleft\arraybackslash}X|>{\raggedright\arraybackslash}X|}
        \hline
        Modèle & intel i7-8550U \\
        \hline
        Architecture & x86\_64 \\
        \hline
        OS & Archlinux \\
        \hline
        Fréquence CPU & 3.4GHz \\
        \hline
        C\oe urs (physique / logique) & 4 / 8 \\
        \hline
        Ram & 16 Go, 2400 $MT/s$ \\
        \hline
        GPU & Intel(R) UHD Graphics 620 \\
        \hline
        OpenCL & version 3.0 \\
        \hline
        GCC & version 11.2.0 \\
        \hline
        nvc++ & version 22.1 \\
        \hline
    \end{tabularx}
\end{center}

\section{Résultats obtenus}

\subsection{OpenCL}

\begin{center}
    \begin{tabularx}{\textwidth}{c c}
        \begin{tikzpicture}[scale=0.8, transform shape]
            \begin{axis}[
                title={Inversion de matrix 1024, temps vs nombre processus},
                xlabel={Nombre de processus},
                ylabel={Temps (sec)},
                xmin=1, xmax=4,
                ymin=0, ymax=40,
                xtick={1, 2, 3, 4},
                ytick={0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40},
                legend pos=north west,
                ymajorgrids=true,
                grid style=dashed,
                ]
                \addplot[color=blue, mark=o] coordinates {(1, 38.8119)(4, 38.8119)};
                \addplot[color=purple, mark=o] coordinates {(1, 36.7437)(2, 22.4539)(3, 18.0343)(4, 15.5994)};

                \legend{Séquentiel, Parallèle}
            \end{axis}
        \end{tikzpicture}
        &
        \begin{tikzpicture}[scale=0.8, transform shape]
            \begin{axis}[
                title={Speedup \& efficacité vs nombre de threads},
                xlabel={Nombre de processus},
                ylabel={Speedup / efficacité},
                xmin=1, xmax=4,
                ymin=0, ymax=3,
                xtick={1,2,3,4},
                ytick={0, 0.5, 1, 1.5, 2, 2.5, 3},
                legend pos=north west,
                ymajorgrids=true,
                grid style=dashed,
                ]
                \addplot[color=blue, mark=o] coordinates {(1, 1)(2, 1.728514868)(3, 2.152115691)(4, 2.488038001)};
                \addplot[color=red, mark=] coordinates {(1, 1)(2, 0.8642574341)(3, 0.7173718969)(4, 0.6220095004)};
                \addplot[color=gray, dotted, ultra thick] coordinates {(0, 1)(8, 1)};
                \legend{Speedup, Efficacité}
            \end{axis}
        \end{tikzpicture}
    \end{tabularx}
\end{center}

\subsection{OpenACC}

\begin{figure}
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[
                xmode=log,
                ymode=log,
                log basis x={2},
                title={Temps d'exécution vs taille de la matrice},
                xlabel={Taille de la matrice},
                ylabel={Temps d'exécution (en s)},
                xmin=16, xmax=2048,
                ymin=0, ymax=12,
                xtick={16,32,64,128, 256, 512, 1024, 2048},
                ytick={0, 0.01, 0.1, 1, 10},
                legend pos=north west,
                ymajorgrids=true,
                grid style=dashed,
                xticklabels={16,32,64,128, 256, 512, 1024, 2048},
                ]
                \addplot[color=blue, mark=o] coordinates {(16, 0.00338412)(32,0.000947176)(64,0.000740214)(128,0.00253456)(256,0.0116102)(512,0.0637085)(1024,1.0821)(2048,11.1209)};
                \legend{Temps d'exécution}
            \end{axis}
        \end{tikzpicture}
    \end{center}
\end{figure}
    
    
    \newpage
    
\section{Analyse}


\section{Conclusion}

\end{document}